{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JDBC API Write Benchmark\n",
    "\n",
    "Import needed packets and set connections up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import columnStoreExporter, time\n",
    "import mysql.connector as mariadb\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row, SQLContext\n",
    "from pyspark.sql.functions import rand, randn, sha1, sha2, md5\n",
    "\n",
    "url = 'jdbc:mysql://columnstore:3306'\n",
    "properties = {'user': 'root', 'driver': 'org.mariadb.jdbc.Driver'}\n",
    "\n",
    "sc = SparkContext(\"local\", \"MariaDB Spark ColumnStore Benchmark\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# SampleDataframe size parameter:\n",
    "asciiRange = 128\n",
    "randRange = 1000\n",
    "hashRange = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = mariadb.connect(user='root', host='columnstore')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DROP DATABASE IF EXISTS benchmark\")\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS benchmark\")\n",
    "\n",
    "except mariadb.Error as err:\n",
    "    print(\"Error while preparing the database for the benchmark. %s\" %(err,))\n",
    "\n",
    "finally:\n",
    "    if cursor: cursor.close()\n",
    "    if conn: conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the sample dataframes to insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asciiDF = sqlContext.createDataFrame(sc.parallelize(range(0, asciiRange)).\\\n",
    "                                     map(lambda i: Row(number=i, ascii_representation=chr(i)))).cache()\n",
    "asciiDF.count()\n",
    "asciiDF.printSchema()\n",
    "randDF = sqlContext.range(0, randRange).withColumn('uniform', rand(seed=23)).withColumn('normal', randn(seed=42)).cache()\n",
    "randDF.count()\n",
    "randDF.printSchema()\n",
    "tmpDF = sqlContext.createDataFrame(sc.parallelize(range(0, hashRange)).map(lambda i: Row(number=i, string=str(i))))\n",
    "hashDF = tmpDF.select(tmpDF.number, sha1(tmpDF.string).alias(\"sha1\"), sha2(tmpDF.string,256).alias(\"sha256\"),\\\n",
    "                      sha2(tmpDF.string,512).alias(\"sha512\"), md5(tmpDF.string).alias(\"md5\")).cache()\n",
    "hashDF.count()\n",
    "hashDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark the insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createColumnStoreAPITable(name, schema):\n",
    "    try:\n",
    "        conn = mariadb.connect(user='root', database='benchmark', host='columnstore')\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"CREATE TABLE IF NOT EXISTS %s (%s) engine=columnstore\" %(name,schema))\n",
    "\n",
    "    except mariadb.Error as err:\n",
    "        print(\"Error while creating the columnstore database %s for the benchmark. %s\" %(name,err,))\n",
    "    \n",
    "    finally:\n",
    "        if cursor: cursor.close()\n",
    "        if conn: conn.close()\n",
    "\n",
    "def benchmark(name, dataframe, schema):\n",
    "    t = time.time()\n",
    "    dataframe.write.option(\"createTableOptions\", \"ENGINE=innodb\")\\\n",
    "    .option(\"createTableColumnTypes\", schema).jdbc(url, \"benchmark.jdbc_innodb_%s\" %(name,), properties=properties)\n",
    "    jdbc_innodb_time = time.time() - t\n",
    "    t = time.time()\n",
    "    dataframe.write.option(\"numPartitions\", 1).option(\"createTableOptions\", \"ENGINE=columnstore\")\\\n",
    "    .option(\"createTableColumnTypes\", schema).jdbc(url, \"benchmark.jdbc_columnstore_%s\" %(name,), properties=properties)\n",
    "    jdbc_columnstore_time = time.time() - t\n",
    "    t = time.time()\n",
    "    createColumnStoreAPITable(\"api_columnstore_%s\" %(name,), schema)\n",
    "    columnStoreExporter.export(\"benchmark\",\"api_columnstore_%s\" %(name,),dataframe)\n",
    "    api_columnstore_time = time.time() - t\n",
    "    return jdbc_innodb_time, jdbc_columnstore_time, api_columnstore_time\n",
    "\n",
    "ascii_benchmark = benchmark(\"ascii\", asciiDF, \"ascii_representation CHAR(1), number INT\")\n",
    "rand_benchmark = benchmark(\"rand\", randDF, \"id BIGINT, uniform DOUBLE, normal DOUBLE\")\n",
    "hash_benchmark = benchmark(\"hash\", hashDF, \"number BIGINT, sha1 VARCHAR(40), sha256 VARCHAR(64), sha512 VARCHAR(128), md5 VARCHAR(32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the comparison in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"jdbc_innodb\\tjdbc_columnstore\\tapi_columnstore\\t\\trows\\t\\titems\")\n",
    "print(\"%.3fs\\t\\t%.3fs\\t\\t\\t%.3fs\\t\\t\\t%i\\t\\t%i\" %(ascii_benchmark[0], ascii_benchmark[1], ascii_benchmark[2], asciiDF.count(), asciiDF.count()*len(asciiDF.columns)))\n",
    "print(\"%.3fs\\t\\t%.3fs\\t\\t\\t%.3fs\\t\\t\\t%i\\t\\t%i\" %(rand_benchmark[0], rand_benchmark[1], rand_benchmark[2], randDF.count(), randDF.count()*len(randDF.columns)))\n",
    "print(\"%.3fs\\t\\t%.3fs\\t\\t\\t%.3fs\\t\\t\\t%i\\t\\t%i\" %(hash_benchmark[0], hash_benchmark[1], hash_benchmark[2], hashDF.count(), hashDF.count()*len(hashDF.columns)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
